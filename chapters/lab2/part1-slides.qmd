---
title: "Part 1: Introduction to T-Tests"
subtitle: "Lab 2: T-Tests"
format:
  revealjs:
    slide-number: true
    progress: true
    hash: true
    transition: fade
    scrollable: true
    width: 1280
    height: 720
    theme: default
    logo: ../../assets/images/GoldLogo.png
    footer: "GoldPsychR - Lab 2, Part 1"
    embed-resources: false
    code-line-numbers: false
    highlight-style: github
filters:
  - webr
  - countdown
webr:
  packages: []
  show-startup-message: false
css: |
  pre code {
    white-space: pre-wrap;
    word-wrap: break-word;
  }
---

## How This Lab Works: Watch → Try → Do {.center background-color="#2C3E50"}

Every part of this lab follows the same **3-step cycle**:

:::::: columns
::: {.column width="33%"}
### 1. Watch

**Instructor Demo**

I'll show you how t-tests work using interactive slides. Watch and follow along!
:::

::: {.column width="33%"}
### 2. Try

**Practice Here**

On the activity page, edit code directly in your browser. Experiment and learn!
:::

::: {.column width="33%"}
### 3. Do

**Your Notebook**

Download the `.qmd` file and complete exercises in RStudio Server. This is your work!
:::
::::::

**This cycle repeats for each part. Let's start!**

---

## Today's Dataset {.center background-color="#27AE60"}

We've collected **Test Anxiety** data from university students:

-   80 students completed the Test Anxiety Inventory
-   Participants were in **Control** or **Intervention** groups
-   Anxiety measured **before and after** the intervention
-   The population mean is known to be **50**

---

## Today's Research Questions

**Our questions**:

1. Does our sample differ from the norm? (one sample)
2. Do the groups differ? (independent)
3. Did anxiety change after intervention? (paired/repeated-measures)

---

## What is a T-Test?

A **t-test** is a statistical test that compares means.

-   Determines if differences are **statistically significant**
-   Accounts for sample size and variability
-   One of the most common statistical tests in psychology

**Key question**: Is the observed difference larger than what we'd expect by chance?

---

## The Logic of Hypothesis Testing

:::: columns
::: {.column width="50%"}
**Null Hypothesis (H₀)**

- States "no effect" or "no difference"
- What we assume is true unless evidence suggests otherwise
- Example: Sample mean = Population mean
:::

::: {.column width="50%"}
**Alternative Hypothesis (H₁)**

- States there IS an effect or difference
- What we're trying to find evidence for
- Example: Sample mean ≠ Population mean
:::
::::

**We test if data provide enough evidence to reject H₀**

---

## P-Values Explained

The **p-value** tells us:

> "If the null hypothesis were true, what's the probability of getting results at least this extreme?"

-   **p < .05**: Results are "statistically significant"
-   **p ≥ .05**: Results are "not statistically significant"

::: {.callout-important}
## Important!
p < .05 doesn't mean "true" - it means "unlikely if H₀ were true"
:::

---

## Types of T-Tests

| Test | Use When | Example |
|------|----------|---------|
| **One-Sample** | Compare sample to known value | Is our sample mean different from 50? |
| **Independent Samples** | Compare two separate groups | Control vs. Intervention groups |
| **Paired Samples** | Compare related measurements | Before vs. After scores |

We'll learn all three today!

---

## Choosing the Right Test

```{mermaid}
%%| echo: false

flowchart TD
    A[Research Question] --> B{How many groups?}
    B -->|One group| C{Comparing to?}
    B -->|Two groups| D{Same or different people?}
    C -->|Known value| E[One-Sample t-test]
    D -->|Different people| F[Independent t-test]
    D -->|Same people| G[Paired t-test]
```

---

## T-Test Assumptions

All t-tests share some assumptions:

1. **Independence**: Observations are independent
2. **Normality**: Data are approximately normally distributed
3. **Scale**: Data are continuous (interval/ratio)

**Additional for independent t-test:**

4. **Equal variances**: Groups have similar spread (can use Welch's test if not)

---

## The t Statistic

$$t = \frac{\text{Observed difference}}{\text{Standard error}}$$

-   **Numerator**: How big is the difference?
-   **Denominator**: How much variability is there?

Large |t| values → More evidence against H₀

---

## Explore: T-Test Adventure {background-color="#f0f0f0"}

Before diving into code, build your intuition about how t-tests work!

::: {.callout-tip}
## Interactive Learning Tool

**[T-Test Adventure](https://oybc0p-gordon-wright.shinyapps.io/ttest_adventure/){target="_blank"}** - An interactive Shiny app where you can experiment with sample sizes, means, and variability to see how they affect t-test results.

Play with the sliders and watch the t-statistic and p-value change in real-time. This helps you understand *why* we get significant results (or not) before you learn the formulas.
:::

---

## Preview: One-Sample T-Test {background-color="#f0f0f0"}

Let me show you what a t-test looks like in R:

::: {.panel-tabset}

### {{< fa code >}} Interactive

```{webr-r}
#| warning: false
#| message: false
# Create sample data
set.seed(42)
scores <- round(rnorm(20, mean = 55, sd = 10))

# One-sample t-test: Is mean different from 50?
t.test(scores, mu = 50)
```

### {{< fa file-code >}} Static

```{webr-r}
#| autorun: true
#| read-only: true
#| warning: false
#| message: false
# Create sample data
set.seed(42)
scores <- round(rnorm(20, mean = 55, sd = 10))

# One-sample t-test: Is mean different from 50?
t.test(scores, mu = 50)
```

### {{< fa lightbulb >}} Explained

```{webr-r}
#| context: output
#| warning: false
#| message: false
set.seed(42)
scores <- round(rnorm(20, mean = 55, sd = 10))
result <- t.test(scores, mu = 50)
p_text <- if(result$p.value < 0.001) "p < .001" else paste0("p = ", round(result$p.value, 3))

cat("Your t-value of", round(result$statistic, 2), "tells us how many standard errors\n")
cat("your sample mean sits from the test value of 50. With", result$parameter, "degrees\n")
cat("of freedom (that's n - 1, so you had", result$parameter + 1, "observations), this\n")
cat("gives us ", p_text, ".\n\n", sep = "")

cat("In your results section, you'd write: 'A one-sample t-test revealed that\n")
cat("scores (M = ", round(mean(scores), 2), ") differed significantly from the\n", sep = "")
cat("population benchmark, t(", result$parameter, ") = ", round(result$statistic, 2),
    ", ", p_text, ".'\n\n", sep = "")

cat("The degrees of freedom come from your sample size minus one - this helps\n")
cat("readers gauge how much data you had. R uses a two-tailed test by default,\n")
cat("which is usually what you want unless you had a strong directional prediction.")
```

:::

---

## Reading the Output

Key values to find:

-   **t = **: The t statistic
-   **df = **: Degrees of freedom (n - 1)
-   **p-value = **: The probability value
-   **95% CI**: Confidence interval for the mean

::: {.callout-tip}
## Decision Rule
If p < .05, reject H₀ and conclude there IS a significant difference
:::

---

## Download the Exercise Notebook

At the end of this part, you will download the `.qmd` notebook file.

**What happens:** The file `lab2-exercise.qmd` will download to your Downloads folder.

**Then:**
1. Log in to RStudio Server
2. Create a folder called `RLab2`
3. Upload the `.qmd` file
4. Open it and change your name

---

## Summary: Part 1 {.center background-color="#2C3E50"}

We've covered:

-   What t-tests are and when to use them
-   The logic of null hypothesis significance testing
-   The three types of t-tests (one-sample, independent, paired)
-   How to read t-test output in R
-   How to download and set up the exercise notebook

---

## Now It's Your Turn! {.center background-color="#9B1B30"}

Open the activity page for Part 1 and work through the **Try It Yourself** exercises.

{{< countdown "10:00" start_immediately="true" >}}

::: {.callout-tip}
## Tips

-   **Edit code directly** in the WebR cells on the page
-   Complete the self-assessment before moving on
-   **Download the exercise notebook** and set it up in RStudio Server
:::
