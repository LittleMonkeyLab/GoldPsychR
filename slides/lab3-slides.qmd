---
title: "Lab 3: ANOVA"
subtitle: "Analysis of Variance - Comparing Multiple Groups"
format:
  revealjs:
    theme: default
    logo: ../assets/images/GoldLogo.png
    footer: "GoldPsychR - Lab 3: ANOVA"
    slide-number: true
    preview-links: auto
    code-line-numbers: false
    highlight-style: github
    scrollable: true
    width: 1050
    height: 700
    transition: fade
---

## Lab 3 Overview {.center}

**Today: ANOVA - Comparing Three or More Groups**

---

## Learning Objectives

By the end of this lab, you will be able to:

1. **Explain** when to use ANOVA instead of t-tests
2. **Conduct** one-way ANOVA in R
3. **Perform** Tukey's HSD post-hoc tests
4. **Run** two-way (factorial) ANOVA with interactions
5. **Calculate** eta-squared (Î·Â²) effect sizes
6. **Write** APA-style ANOVA results

---

## The Dataset: Study Techniques

**Research Question**: Do different study methods affect memory recall?

- **120 university students**
- **3 study methods**: Rereading, Self-Testing, Elaboration
- **2 time periods**: Morning or Evening
- **Outcome**: Items recalled (0-30)

---

## Why Not Multiple t-tests?

Comparing 3 groups means 3 pairwise comparisons:

- Group 1 vs Group 2
- Group 1 vs Group 3
- Group 2 vs Group 3

**Problem**: Each test at Î± = .05 inflates overall error rate!

$$\text{Family-wise error} = 1 - (1 - .05)^3 = .14$$

**ANOVA controls this!**

---

# Part 1: One-Way ANOVA

---

## The Logic of ANOVA

ANOVA compares **between-group variance** to **within-group variance**

$$F = \frac{\text{Between-group variance}}{\text{Within-group variance}}$$

- Large F â†’ Groups differ more than expected by chance
- Small F â†’ Differences could be due to random variation

---

## Loading the Data

```r
library(readr)
library(dplyr)
library(ggplot2)

# Load from GitHub
data_url <- "https://raw.githubusercontent.com/LittleMonkeyLab/datarepo/main/study_techniques.csv"
study_data <- read_csv(data_url, show_col_types = FALSE)

head(study_data)
```

---

## Descriptives by Group

```r
study_data |>
  group_by(method) |>
  summarise(
    n = n(),
    mean = mean(recall, na.rm = TRUE),
    sd = sd(recall, na.rm = TRUE)
  )
```

| Method | n | Mean | SD |
|--------|---|------|-----|
| Rereading | 40 | 14.9 | 4.1 |
| Self-Testing | 40 | 21.5 | 4.2 |
| Elaboration | 40 | 19.7 | 4.5 |

---

## Running One-Way ANOVA

```r
# Fit the model
model1 <- aov(recall ~ method, data = study_data)

# View results
summary(model1)
```

```
            Df Sum Sq Mean Sq F value   Pr(>F)
method       2  899.6   449.8   24.1 6.2e-10 ***
Residuals  117 2183.4    18.7
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

---

## Reading the Output

Key values:

- **Df**: Degrees of freedom (2 between, 117 within)
- **F value**: 24.1 - ratio of variances
- **Pr(>F)**: p-value < .001

**Conclusion**: There IS a significant difference somewhere!

But which groups differ? ðŸ¤”

---

## Visualising the Groups

```r
ggplot(study_data, aes(x = method, y = recall, fill = method)) +
  geom_boxplot(alpha = 0.7) +
  scale_fill_manual(values = c("Elaboration" = "#3498DB",
                                "Rereading" = "#E74C3C",
                                "Self-Testing" = "#27AE60")) +
  theme_minimal() +
  labs(title = "Recall Scores by Study Method",
       x = "Study Method", y = "Items Recalled")
```

---

# Part 2: Post-Hoc Tests

---

## Why Post-Hoc Tests?

ANOVA tells us: "At least one group differs"

**But we need to know WHICH groups differ!**

Post-hoc tests compare all pairs while controlling Type I error

---

## Tukey's HSD

HSD = "Honest Significant Difference"

```r
# Run Tukey's test
tukey_results <- TukeyHSD(model1)
tukey_results
```

---

## Tukey Output

```
  Tukey multiple comparisons of means
    95% family-wise confidence level

$method
                            diff       lwr       upr     p adj
Rereading-Elaboration      -4.8     -7.3    -2.3    0.0001
Self-Testing-Elaboration    1.8     -0.7     4.3    0.2180
Self-Testing-Rereading      6.6      4.1     9.1    0.0000
```

---

## Interpreting Tukey Results

| Comparison | diff | p adj | Significant? |
|------------|------|-------|--------------|
| Rereading vs Elaboration | -4.8 | .0001 | âœ“ Yes |
| Self-Testing vs Elaboration | 1.8 | .22 | âœ— No |
| Self-Testing vs Rereading | 6.6 | <.0001 | âœ“ Yes |

**Conclusion**: Self-Testing and Elaboration are both better than Rereading, but don't differ from each other.

---

## Visualising Tukey Results

```r
plot(tukey_results)
```

Intervals that cross zero = NOT significant

---

# Part 3: Two-Way ANOVA

---

## Factorial Designs

When you have **two factors**:

- **Factor A**: Study Method (3 levels)
- **Factor B**: Time of Day (2 levels)

Design: 3 Ã— 2 = **6 cells**

---

## What Can We Test?

**Three questions in one analysis:**

1. **Main effect of Method**: Do methods differ (averaging over time)?
2. **Main effect of Time**: Does time matter (averaging over method)?
3. **Interaction**: Does the effect of method depend on time?

---

## Running Two-Way ANOVA

```r
# Use * to include interaction
model2 <- aov(recall ~ method * time_of_day, data = study_data)

summary(model2)
```

---

## Two-Way ANOVA Output

```
                    Df Sum Sq Mean Sq F value   Pr(>F)
method               2  899.6  449.80  23.42 2.1e-09 ***
time_of_day          1   62.8   62.80   3.27   0.073
method:time_of_day   2   11.2    5.60   0.29   0.748
Residuals          114 2188.4   19.20
```

---

## Interpreting the Results

| Effect | F | p | Interpretation |
|--------|---|---|----------------|
| Method | 23.42 | <.001 | âœ“ Significant main effect |
| Time | 3.27 | .073 | âœ— Not significant |
| Interaction | 0.29 | .748 | âœ— Not significant |

**Method matters, but time of day doesn't, and the pattern is consistent across times.**

---

## What is an Interaction?

**No interaction**: The effect of A is the same at all levels of B

**Interaction present**: The effect of A **depends on** the level of B

Example with interaction:
- Self-testing works great in the morning
- Self-testing is worse in the evening
- The effect of method **changes** with time

---

## Interaction Plots

```r
interaction.plot(study_data$time_of_day, study_data$method,
                 study_data$recall,
                 type = "b",
                 xlab = "Time of Day", ylab = "Mean Recall",
                 col = c("blue", "red", "green"), lwd = 2)
```

**Parallel lines** = No interaction

**Crossing/diverging lines** = Interaction

---

# Part 4: Effect Sizes

---

## Beyond p-values

A significant F tells us groups differ.

But **how much** do they differ?

**Eta-squared (Î·Â²)** = proportion of variance explained

---

## Calculating Eta-Squared

$$\eta^2 = \frac{SS_{effect}}{SS_{total}}$$

```r
# Extract from summary
s <- summary(model1)

ss_method <- s[[1]]["method", "Sum Sq"]
ss_residual <- s[[1]]["Residuals", "Sum Sq"]
ss_total <- ss_method + ss_residual

eta_sq <- ss_method / ss_total
cat("Î·Â² =", round(eta_sq, 3))
```

---

## Cohen's Guidelines for Î·Â²

| Î·Â² | Interpretation |
|----|----------------|
| 0.01 | Small |
| 0.06 | Medium |
| 0.14 | Large |

Our Î·Â² â‰ˆ 0.29 â†’ **Large effect**

Study method explains ~29% of variance in recall!

---

## Partial Eta-Squared

For **factorial designs**, use partial eta-squared:

$$\eta^2_p = \frac{SS_{effect}}{SS_{effect} + SS_{error}}$$

Controls for other factors in the model.

---

# Part 5: APA Reporting

---

## One-Way ANOVA Template

> A one-way ANOVA revealed a [significant/non-significant] effect of [factor] on [DV], *F*(df1, df2) = F-value, *p* = p-value, Î·Â² = effect-size.

---

## Example Write-Up

> A one-way ANOVA revealed a significant effect of study method on recall performance, *F*(2, 117) = 24.10, *p* < .001, Î·Â² = .29. Post-hoc comparisons using Tukey's HSD indicated that self-testing (*M* = 21.5, *SD* = 4.2) and elaboration (*M* = 19.7, *SD* = 4.5) both resulted in significantly higher recall than rereading (*M* = 14.9, *SD* = 4.1), *p*s < .001. Self-testing and elaboration did not differ significantly (*p* = .22).

---

## Two-Way ANOVA Template

> A 3 Ã— 2 ANOVA examined the effects of [factor A] and [factor B] on [DV]. There was a significant main effect of [factor A], *F*(df1, df2) = F, *p* = p, Î·Â²_p = value. The main effect of [factor B] was [not] significant. The interaction was [not] significant.

---

## Common Reporting Mistakes

1. **Forgetting effect sizes** - Always report Î·Â² or Î·Â²_p
2. **Wrong df order** - It's F(between, within)
3. **Not rounding appropriately** - F to 2 decimal places
4. **Missing post-hocs** - Need them to specify which groups differ
5. **Over-interpreting non-significant effects**

---

## Summary: What You've Learned

- âœ… When to use ANOVA vs t-tests
- âœ… Running one-way ANOVA with `aov()`
- âœ… Post-hoc comparisons with `TukeyHSD()`
- âœ… Two-way factorial ANOVA
- âœ… Interpreting interactions
- âœ… Calculating eta-squared
- âœ… APA-style reporting

---

## Now Complete Your Exercises!

::: {.callout-tip}
## Tasks

1. Open your exercise notebook
2. Complete all parts following the Watch â†’ Try â†’ Do cycle
3. Calculate effect sizes for all analyses
4. Write APA results sections
5. **Render to HTML** and check your work!
:::

---

## Questions? {.center}

Ask your instructor or check with your lab partner!
